# digital-humanities-novel-database
A digital humanities project comparing AI-generated and human-authored Chinese xianxia/xiuzhen novels. Includes curated metadata (title, author, platform, genre, excerpt) and links to an interactive Airtable view for filtering, comparing, and visualizing data. 
# Digital Humanities: AI vs Human Novels (Metadata Hub)

A public, explorable dataset & hub for my digital humanities project comparing **AI-generated** and **human-authored** xianxia/xiuzhen fiction.  
üëá Explore the interactive database & charts:

üëâ **Interactive View (Voyant):** [(https://voyant-tools.org/?corpus=0d1c91e75ffa0b14cc37dd1801c88960&panels=cirrus,reader,trends,summary,contexts)]](https://voyant-tools.org/?corpus=3113b8b25a46d2fd2196838d0ae7762d&panels=cirrus,reader,trends,summary,contexts)
üëâ **Xianxia Glossary (wordpress):** https://immortalmountain.wordpress.com/glossary/wuxia-xianxia-xuanhuan-terms/



---

## What‚Äôs inside
- **Metadata fields:** `id`, `title`, `author`, `platform`, `source_url`, `ai_or_human`, `genre`, `year`, `word_count`, `excerpt`, `notes`, `encoding`
- **Sampling:** AI and human novels (e.g., xiuzhen/xiƒÅnxi√°); short excerpts (‚â§200 chars) for fair use and analysis.
- **Planned analyses:** sentiment trend, topic distribution, lexical diversity; case studies with annotations; methodology & mindful practice notes.

## Data dictionary
- `ai_or_human`: `ai` or `human`  
- `genre`: controlled tags (e.g., ‰øÆ‰ªô/ÁéÑÂπª/ÈÉΩÂ∏Ç)  
- `excerpt`: short representative passage for qualitative & lightweight quantitative analysis  
- `word_count`: character count (approx., when available)

## Cite / Acknowledge
If you use this dataset or interface, please cite:
- Wang, Yixuan (2025). *AI vs Human Novels: A Digital Humanities Dataset*.  
  GitHub: this repo. Interactive view via Airtable.

## Ethics & Copyright
- Excerpts are short for scholarly ‚Äúfair use‚Äù; full texts are **not** redistributed.  
- Sources linked via `platform` / `source_url` when available.  
- Please open an issue for takedown or corrections.

## Changelog
- 2025-09-22: Initial release with baseline metadata and interactive view.

## License
- Metadata (this repository): CC BY 4.0  
- Embedded/linked platform content: subject to the original platforms‚Äô terms.

- # 11/17/2025 Updated: Seeing Like a Machine: A Small-Corpus Digital Reading of AI-Generated Xianxia Fiction

This project explores what digital tools can reveal about how AI ‚Äúwrites‚Äù a xianxia novel.

Rather than building a large dataset, I work with a **very small corpus**:
- one short **AI-generated** xianxia excerpt
- one **human-authored** xianxia excerpt of comparable length  


---

## Research Questions

- What distinctive patterns appear when AI fiction is examined through digital tools?  
- How do emotional vocabulary and stylistic choices differ between AI and human texts?  
- How does reading through computation reshape our understanding of AI authorship?

---

## Methods

### Corpus

- Two short Chinese-language xianxia excerpts  
- Cleaned into plain-text files (`AI.txt`, `Human.txt`) for analysis  

### Tools

- **Voyant Tools**
  - *Cirrus* ‚Äì overall word frequency profile  
  - *Trends* ‚Äì emotional / psychological keywords over narrative time  

  

### Workflow

1. Build a small, interpretable two-text corpus (AI vs human).  
2. Upload both texts to Voyant and generate visualizations (word clouds, trends, contexts).  
3. Run a Java script to detect low-frequency characters and filter out common ones.  
4. Compare:
   - rare-character density (doing) 
   - emotional vocabulary  
   - formulaic action phrases vs introspective language  
5. Use these patterns to guide **close reading** of selected passages.

---

## Preliminary Findings

- The **AI text** contains a high density of rare characters, many appearing only once or twice.  
- The **human text** uses a less richer set of emotional and psychological verbs (e.g., ÊÉ≥, Êúõ, Áñë, Âèπ), giving it more interiority.    
- These patterns became visible **because of digital methods**‚Äîthey are easy to miss in ordinary close reading.

---

## Next Steps
  
- Build a small emotional-word list for more systematic comparisons.  
- Categorize rare characters:
  - archaic  
  - genre-specific  
  - seemingly ‚Äúmachine-invented‚Äù or odd  
- Integrate more close reading to connect visual patterns to concrete passages.

---

## Reflections on Digital Humanities

- **Digital methods are not neutral.**  
  Voyant makes some features (frequency, repetition, rarity) very visible, while hiding others (plot structure, character development). Reading digitally means accepting the tool‚Äôs assumptions.

- **Small data can still matter.**  
  A tiny corpus can generate meaningful insights when the goal is interpretation rather than prediction. It also keeps the project manageable and mindful.

- **AI authorship becomes a pattern, not a mystery.**  
  Through rare-character spikes, emotional vocabulary, and repetition patterns, AI writing appears as something we can analyze, question, and understand‚Äîrather than a purely opaque ‚Äúblack box.‚Äù

  ## üåü Project Update ‚Äî December 9, 2025

This final update reflects a refined direction for my Digital Humanities project. Over the semester, my focus has shifted from building a large comparative database to developing a **small-corpus, interpretive, and tool-assisted reading of AI vs. human xianxia fiction**.

This version of the project emphasizes:
- üß≠ A clearer research question about *narrative logic* and *emotional structure*
- üìä The use of **Voyant Tools** (Trends, Bubblelines) to reveal stylistic and structural patterns
- ‚ú® A new set of **geometric visual signatures** that distinguish human teleology from AI stochasticity
- üî† A computational replication using Python that models how emotional density shifts across narrative time

Rather than trying to ‚Äúprove‚Äù whether AI can write like a human, this update frames the project as an exploration of **what becomes visible when we read through machines**‚Äîand how narrative patterns differ when authorship is algorithmic versus intentional.

This README now includes:
- A reorganized project overview  
- Updated methodology and corpus description  
- Summarized key findings  
- A Python snippet that reconstructs the logic behind Voyant‚Äôs relative-frequency analysis  

This version represents my final DH project for Fall 2025, highlighting both digital technique and humanistic interpretation.


---

*This repository accompanies a course project in digital humanities and is meant as an experiment in thinking about AI style, and machine-assisted reading.*

