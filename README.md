# digital-humanities-novel-database
A digital humanities project comparing AI-generated and human-authored Chinese xianxia/xiuzhen novels. Includes curated metadata (title, author, platform, genre, excerpt) and links to an interactive Airtable view for filtering, comparing, and visualizing data. 
# Digital Humanities: AI vs Human Novels (Metadata Hub)

A public, explorable dataset & hub for my digital humanities project comparing **AI-generated** and **human-authored** xianxia/xiuzhen fiction.  
ğŸ‘‡ Explore the interactive database & charts:

ğŸ‘‰ **Interactive View (Voyant):** [[(https://voyant-tools.org/?corpus=0d1c91e75ffa0b14cc37dd1801c88960&panels=cirrus,reader,trends,summary,contexts)]](https://voyant-tools.org/?corpus=3113b8b25a46d2fd2196838d0ae7762d&panels=cirrus,reader,trends,summary,contexts)](https://voyant-tools.org/?corpus=3113b8b25a46d2fd2196838d0ae7762d&panels=cirrus,reader,trends,summary,contexts)
ğŸ‘‰ **Xianxia Glossary (wordpress):** https://immortalmountain.wordpress.com/glossary/wuxia-xianxia-xuanhuan-terms/



---

## Whatâ€™s inside
- **Metadata fields:** `id`, `title`, `author`, `platform`, `source_url`, `ai_or_human`, `genre`, `year`, `word_count`, `excerpt`, `notes`, `encoding`
- **Sampling:** AI and human novels (e.g., xiuzhen/xiÄnxiÃ¡); short excerpts (â‰¤200 chars) for fair use and analysis.
- **Planned analyses:** sentiment trend, topic distribution, lexical diversity; case studies with annotations; methodology & mindful practice notes.

## Data dictionary
- `ai_or_human`: `ai` or `human`  
- `genre`: controlled tags (e.g., ä¿®ä»™/ç„å¹»/éƒ½å¸‚)  
- `excerpt`: short representative passage for qualitative & lightweight quantitative analysis  
- `word_count`: character count (approx., when available)

## Cite / Acknowledge
If you use this dataset or interface, please cite:
- Wang, Yixuan (2025). *AI vs Human Novels: A Digital Humanities Dataset*.  
  GitHub: this repo. Interactive view via Airtable.

## Ethics & Copyright
- Excerpts are short for scholarly â€œfair useâ€; full texts are **not** redistributed.  
- Sources linked via `platform` / `source_url` when available.  
- Please open an issue for takedown or corrections.

## Changelog
- 2025-09-22: Initial release with baseline metadata and interactive view.

## License
- Metadata (this repository): CC BY 4.0  
- Embedded/linked platform content: subject to the original platformsâ€™ terms.

- # 11/17/2025 Updated: Seeing Like a Machine: A Small-Corpus Digital Reading of AI-Generated Xianxia Fiction

This project explores what digital tools can reveal about how AI â€œwritesâ€ a xianxia novel.

Rather than building a large dataset, I work with a **very small corpus**:
- one short **AI-generated** xianxia excerpt
- one **human-authored** xianxia excerpt of comparable length  


---

## Research Questions

- What distinctive patterns appear when AI fiction is examined through digital tools?  
- How do emotional vocabulary and stylistic choices differ between AI and human texts?  
- How does reading through computation reshape our understanding of AI authorship?

---

## Methods

### Corpus

- Two short Chinese-language xianxia excerpts  
- Cleaned into plain-text files (`AI.txt`, `Human.txt`) for analysis  

### Tools

- **Voyant Tools**
  - *Cirrus* â€“ overall word frequency profile  
  - *Trends* â€“ emotional / psychological keywords over narrative time  

  

### Workflow

1. Build a small, interpretable two-text corpus (AI vs human).  
2. Upload both texts to Voyant and generate visualizations (word clouds, trends, contexts).  
3. Run a Java script to detect low-frequency characters and filter out common ones.  
4. Compare:
   - rare-character density (doing) 
   - emotional vocabulary  
   - formulaic action phrases vs introspective language  
5. Use these patterns to guide **close reading** of selected passages.

---

## Preliminary Findings

- The **AI text** contains a high density of rare characters, many appearing only once or twice.  
- The **human text** uses a less richer set of emotional and psychological verbs (e.g., æƒ³, æœ›, ç–‘, å¹), giving it more interiority.    
- These patterns became visible **because of digital methods**â€”they are easy to miss in ordinary close reading.

---

## Next Steps
  
- Build a small emotional-word list for more systematic comparisons.  
- Categorize rare characters:
  - archaic  
  - genre-specific  
  - seemingly â€œmachine-inventedâ€ or odd  
- Integrate more close reading to connect visual patterns to concrete passages.

---

## Reflections on Digital Humanities

- **Digital methods are not neutral.**  
  Voyant makes some features (frequency, repetition, rarity) very visible, while hiding others (plot structure, character development). Reading digitally means accepting the toolâ€™s assumptions.

- **Small data can still matter.**  
  A tiny corpus can generate meaningful insights when the goal is interpretation rather than prediction. It also keeps the project manageable and mindful.

- **AI authorship becomes a pattern, not a mystery.**  
  Through rare-character spikes, emotional vocabulary, and repetition patterns, AI writing appears as something we can analyze, question, and understandâ€”rather than a purely opaque â€œblack box.â€

  ## ğŸŒŸ Project Update â€” December 9, 2025 (emotion words updates)

This final update reflects a refined direction for my Digital Humanities project. Over the semester, my focus has developed to make a **interpretive, and tool-assisted reading of AI vs. human xianxia fiction**.

This version of the project emphasizes:
- ğŸ§­ A clearer research question about *narrative logic* and *emotional structure*
- ğŸ“Š The use of **Voyant Tools** (Trends, Bubblelines) to reveal stylistic and structural patterns
- âœ¨ A new set of **geometric visual signatures** that distinguish human teleology from AI stochasticity
- ğŸ”  A computational replication using Python that helped to figure out how Chinese words can be successflully telled by Voyant
- 
- 

Rather than trying to â€œproveâ€ whether AI can write like a human, this update frames the project as an exploration of **what becomes visible when we read through machines**â€”and how narrative patterns differ when authorship is algorithmic versus intentional.

 Emotions & Sensations words
1. (Positive Emotions): ç¬‘ (Laugh / Smile), é«˜å…´ (Happy / Glad), æ¬¢ (Joy / Delight), å–œ (Happy / Joyful), ä¹ (Joy / Fun), å…´ (Excitement / Interest), æ‚¦ (Delight / Pleased), çˆ± (Love), æŸ” (Gentle / Soft), æ¸©æŸ” (Tenderness / Gentle), æ»¡æ„ (Satisfied / Content), æ¬£å–œ (Ecstatic / Joyfully surprised), æ¬£æ…° (Relieved / Gratified), æ„‰ (Pleasant / Cheerful), æ„‰å¿« (Happy / Cheerful), å…´å¥‹ (Excited), æ¿€åŠ¨ (Agitated / Thrilled / Emotional)

2.  (Negative Emotions): è‹¦ (Bitter / Suffering), ç—› (Pain), ç—›è‹¦ (Suffering / Agony), å“­ (Cry), æ³ª (Tears), æ‚² (Sad / Sorrow), æ‚²ä¼¤ (Sorrow / Sadness), å“€ (Grief / Mourning), æ„ (Worry / Melancholy), æ€’ (Anger / Rage), æ¨ (Hate / Hatred), æ€¨ (Resentment), æ† (Detest / Abhor), æ (Fear / Dread), æ€• (Scared / Afraid), æƒ§ (Fear), æƒŠ (Surprise / Shock / Fright), ç´¯ (Tired / Weary), ç–² (Fatigue / Exhausted), å¿ƒé…¸ (Heartbroken / Poignant), éš¾è¿‡ (Sad / Upset), å†·é…· (Cold-blooded / Ruthless)

3. (States & Cognition): æƒ³ (Think / Miss), æ„Ÿ (Feel / Sense), è§‰ (Feel / Perceive), ææƒš (Trance / Absent-minded), çŠ¹è±« (Hesitate), å¥½å¥‡ (Curious), å¹³é™ (Calm / Peaceful), å†·é™ (Cool-headed / Calm), è…¼è…† (Shy / Bashful)

This README now includes:
- A reorganized project overview  
- Updated methodology and corpus description  
- Summarized key findings  
- A Python snippet that reconstructs the logic behind Voyantâ€™s relative-frequency analysis
- The Python I have tried to use for adding spaces:
- import jieba

# è¯»å–åŸæ–‡ä»¶
with open('äººèœœ_ä½œè€…_é»‘çŒ«ç™½è¢œå­_3_.txt', 'r', encoding='utf-8') as f:
    text = f.read()

# åˆ†è¯
words = jieba.cut(text)
result = ' '.join(words)

# ä¿å­˜ç»“æœ
with open('äººèœœ_åˆ†è¯ç‰ˆ.txt', 'w', encoding='utf-8') as f:
    f.write(result)

print("åˆ†è¯å®Œæˆï¼")

This version represents my final DH project for Fall 2025, highlighting both digital technique and humanistic interpretation.


---

*This repository accompanies a course project in digital humanities and is meant as an experiment in thinking about AI style, and machine-assisted reading.*

